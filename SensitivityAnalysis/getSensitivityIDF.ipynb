{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dirty-chain",
   "metadata": {},
   "source": [
    "# getSensitivityIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-kazakhstan",
   "metadata": {},
   "source": [
    "The following code outputs a number of objects.\n",
    "<br>\n",
    "<br>\n",
    "<u><b>IDF for jEplus:</b></u>\n",
    "<br>\n",
    "There are a total of 1573 parameters which need to be analysed for the sensitivity analysis. Manually adding the appropriate tags into the IDF so that jEplus knows which parameters to analyse is infeasible. This script takes in the list of parameters from the uncertainty analysis code as well as the building IDF and returns a new IDF with the relevent parameter tags.\n",
    "<br>\n",
    "<br>\n",
    "<u><b>Parameter CSV for jEplus:</b></u>\n",
    "<br>\n",
    "jEplus also requires the parameters which are to be analysed with their respective minimum and maximum values to be defined. This script returns a CSV file listing these parameters which can be directly put into jEplus.\n",
    "<br>\n",
    "<br>\n",
    "<u><b>Jobs CSV for jEplus:</b></u>\n",
    "<br>\n",
    "jEplus requires us to specify the jobs which will be run. This code outputs a CSV file listing all the jobs to be run which can be put into jEplus.\n",
    "<br>\n",
    "<br>\n",
    "<u><b>Parameter JSON File:</b></u>\n",
    "<br>\n",
    "A JSON file which will be used later in the <i>\"SensitivityAnalysis.ipynb\"</i> notebook is also output by this script.\n",
    "<br>\n",
    "<br>\n",
    "<u><b>Extremes Jobs CSV:</b></u>\n",
    "<br>\n",
    "During the calibration process it is possible that a number of parameters will be changed to their maximum/minimum value. To ensure that no errors occur in EnergyPlus when such an IDF is used, it is important to run a simulation where every value is set to an extreme (minimum/maximum). This script outputs another jobs CSV file where each parameter is set to a maximum and minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conceptual-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class JEPlusSensitivityAnalysis():\n",
    "    \n",
    "    def __init__(self, idfFile, iddFile, paramFile):\n",
    "        self.paramFile = paramFile\n",
    "        self.idfFile = idfFile\n",
    "        self.iddFile = iddFile\n",
    "        \n",
    "        self.idf, self.idd = self.getIDFandIDD(self.idfFile, self.iddFile)\n",
    "        \n",
    "        self.full_df = pd.read_csv(paramFile).dropna()\n",
    "        self.initial_df = pd.read_csv(paramFile).loc[:, ['Class', 'Object', 'Field']].dropna()\n",
    "        self.df = self.addTagNumbers(self.initial_df)\n",
    "        self.paramsCSV = self.initial_df.copy()\n",
    "        \n",
    "        self.uniqueClasses = self.df['Class'].unique()\n",
    "        self.classDict = self.getClassDict()\n",
    "        \n",
    "        self.tagNumSanityCheck = []\n",
    "        \n",
    "        self.createJEPlusIDF()\n",
    "        self.jEplusParameters = self.createParameterCSV()\n",
    "        self.jEplusJobs, self.jobsDict, self.minimax_jobs_df = self.createJobsCSVandJSON()\n",
    "        \n",
    "        \n",
    "    def getIDFandIDD(self, idfFile, iddFile):\n",
    "        idf = open(idfFile, \"r\")\n",
    "        initial_idf_lines = idf.readlines()\n",
    "        \n",
    "        initial_idf_copy = []\n",
    "        for line in initial_idf_lines:\n",
    "            newLine = line.strip()\n",
    "            initial_idf_copy.append(newLine)\n",
    "            \n",
    "        idf_lines = self.removeIDFcomments(initial_idf_copy)\n",
    "    \n",
    "        idd = open(iddFile, \"r\")\n",
    "        idd_lines = idd.readlines()\n",
    "    \n",
    "        return idf_lines, idd_lines\n",
    "    \n",
    "    \n",
    "    def extractFields(self, start):\n",
    "        classList = []\n",
    "        num = start\n",
    "        while self.idd[num] != '\\n':\n",
    "            if self.idd[num].strip()[0] == 'A' or self.idd[num].strip()[0] == 'N':\n",
    "                pattern = re.compile(r'\\\\field')\n",
    "                matches = pattern.search(self.idd[num])\n",
    "                \n",
    "                if matches is not None:\n",
    "                    classList.append(self.idd[num].strip().split('\\\\field ')[1])\n",
    "            \n",
    "            num = num + 1\n",
    "        \n",
    "        return classList\n",
    "    \n",
    "    \n",
    "    def getClassDict(self):\n",
    "        classDict = {}\n",
    "        for uniqueClass in self.uniqueClasses:\n",
    "            i = 0\n",
    "            while i < len(self.idd):\n",
    "                line = self.idd[i]\n",
    "                adjLine = line.strip().split(',')[0]\n",
    "            \n",
    "                if adjLine == uniqueClass:\n",
    "                    currentList = self.extractFields(i)\n",
    "                    classDict[uniqueClass] = currentList\n",
    "                    break\n",
    "            \n",
    "                i = i + 1\n",
    "                \n",
    "        return classDict\n",
    "    \n",
    "    \n",
    "    def addTagNumbers(self, df):\n",
    "        dfCopy = df.copy()\n",
    "        tagNums = []\n",
    "        i = 0\n",
    "        while i < len(dfCopy):\n",
    "            tagNums.append(i)\n",
    "            i = i + 1\n",
    "            \n",
    "        dfCopy['Tag Number'] = tagNums\n",
    "        \n",
    "        return dfCopy\n",
    "    \n",
    "    \n",
    "    def removeIDFcomments(self, idf):\n",
    "        idfCopy = []\n",
    "        \n",
    "        for line in idf:\n",
    "            if len(line) == 0:\n",
    "                idfCopy.append(line)\n",
    "        \n",
    "            elif line.strip()[0] != '!':\n",
    "                idfCopy.append(line)\n",
    "                \n",
    "        if len(idfCopy[0]) == 0:\n",
    "            del idfCopy[0]\n",
    "            \n",
    "        return idfCopy\n",
    "    \n",
    "    \n",
    "    def removeComment(self, line):\n",
    "        newLine = re.split('!', line)[0].strip()\n",
    "        \n",
    "        return newLine\n",
    "    \n",
    "    \n",
    "    def getClassObject(self, start):\n",
    "        num = start\n",
    "        line = self.idf[num]\n",
    "        pattern = re.compile(r';')\n",
    "        matches = None\n",
    "        classFields = []\n",
    "        \n",
    "        while matches is None:\n",
    "            lineWithoutComment = self.removeComment(self.idf[num])\n",
    "            currentLine = re.split(',|;', lineWithoutComment)\n",
    "            del currentLine[-1]\n",
    "            \n",
    "            for element in currentLine:\n",
    "                classFields.append(element)\n",
    "            \n",
    "            matches = pattern.search(self.idf[num])\n",
    "            num = num + 1\n",
    "        \n",
    "        classObjectName = classFields[1]\n",
    "        return classObjectName\n",
    "    \n",
    "    \n",
    "    def oneObjectTagAdd(self, start, uniqueClass):\n",
    "        num = start\n",
    "        pattern = re.compile(r';')\n",
    "        matches = None\n",
    "        searchTerms = []\n",
    "        searchTermsDict = {}\n",
    "        elementsPerLine = []\n",
    "    \n",
    "        while matches is None:\n",
    "            count = 0\n",
    "            lineWithoutComment = self.removeComment(self.idf[num])\n",
    "            currentLine = re.split(',|;', lineWithoutComment)\n",
    "            del currentLine[-1]\n",
    "                    \n",
    "            matches = pattern.search(self.idf[num])\n",
    "            for element in currentLine:\n",
    "                searchTerms.append(element.strip())\n",
    "                count = count + 1\n",
    "            \n",
    "            elementsPerLine.append(count)\n",
    "            num = num + 1\n",
    "            \n",
    "        assert searchTerms[0] == uniqueClass, 'Class Mismatch'\n",
    "    \n",
    "        del searchTerms[0]\n",
    "    \n",
    "        searchTermsDict[uniqueClass] = searchTerms\n",
    "        searchTermsDict['ElementsPerLine'] = elementsPerLine\n",
    "    \n",
    "        assert sum(searchTermsDict['ElementsPerLine']) == len(searchTermsDict[uniqueClass]) + 1\n",
    "        \n",
    "        currentDF = self.df.loc[self.df['Class'] == uniqueClass, :]\n",
    "        num = start\n",
    "    \n",
    "        for f in currentDF['Field'].unique():\n",
    "            if f not in self.classDict[uniqueClass]:\n",
    "                print(f'{f} not in {uniqueClass} classDict')\n",
    "    \n",
    "        pat = re.compile('@@')\n",
    "        for val in self.classDict[uniqueClass]:\n",
    "                \n",
    "            if val in currentDF['Field'].unique():\n",
    "                currentIndex = self.classDict[uniqueClass].index(val)\n",
    "                tagNum = currentDF.loc[currentDF['Field'] == val, ['Tag Number']].values[0][0]\n",
    "                \n",
    "                i = 0\n",
    "                j = 0\n",
    "                while i < currentIndex + 2:\n",
    "                    \n",
    "                    lineNow = self.idf[num + j]\n",
    "                    \n",
    "                    i = i + searchTermsDict['ElementsPerLine'][j]\n",
    "                    j = j + 1\n",
    "                \n",
    "                tagged = pat.search(lineNow)\n",
    "                if tagged is None:\n",
    "                    new = new = lineNow.replace(searchTermsDict[uniqueClass][currentIndex], f'@@tag{tagNum}@@', 1)\n",
    "                    \n",
    "                elif tagged is not None:\n",
    "                    lineArray = lineNow.split('@@')\n",
    "                    newLineNow = lineArray[-1]\n",
    "                    del lineArray[-1]\n",
    "                    newt = newLineNow.replace(searchTermsDict[uniqueClass][currentIndex], f'@@tag{tagNum}@@', 1)\n",
    "                    new = '@@'.join(lineArray) + '@@' + newt\n",
    "\n",
    "                self.idf[num + j - 1] = new\n",
    "                self.tagNumSanityCheck.append(tagNum)\n",
    "                \n",
    "    \n",
    "    def multipleObjectTagAdd(self, start, uniqueClass, uniqueObject):\n",
    "        num = start\n",
    "        pattern = re.compile(r';')\n",
    "        matches = None\n",
    "        searchTerms = []\n",
    "        searchTermsDict = {}\n",
    "        elementsPerLine = []\n",
    "        \n",
    "        while matches is None:\n",
    "            count = 0\n",
    "            lineWithoutComment = self.removeComment(self.idf[num])\n",
    "            currentLine = re.split(',|;', lineWithoutComment)\n",
    "            del currentLine[-1]\n",
    "                    \n",
    "            matches = pattern.search(self.idf[num])\n",
    "            for element in currentLine:\n",
    "                searchTerms.append(element.strip())\n",
    "                count = count + 1\n",
    "                \n",
    "            elementsPerLine.append(count)\n",
    "            num = num + 1\n",
    "            \n",
    "        assert searchTerms[0] == uniqueClass, 'Class Mismatch'\n",
    "        assert searchTerms[1] == uniqueObject, 'Object Mismatch'\n",
    "        \n",
    "        del searchTerms[0:2]\n",
    "        \n",
    "        searchTermsDict[f'{uniqueClass} --> {uniqueObject}'] = searchTerms\n",
    "        searchTermsDict['ElementsPerLine'] = elementsPerLine\n",
    "        \n",
    "        assert sum(searchTermsDict['ElementsPerLine']) == len(searchTermsDict[f'{uniqueClass} --> {uniqueObject}']) + 2\n",
    "        \n",
    "        currentDF = self.df.loc[(self.df['Class'] == uniqueClass) & (self.df['Object'] == uniqueObject), :]\n",
    "        num = start\n",
    "        \n",
    "        for f in currentDF['Field'].unique():\n",
    "            if f not in self.classDict[uniqueClass]:\n",
    "                print(f'{f} not in {uniqueClass} classDict')\n",
    "        \n",
    "        pat = re.compile('@@')\n",
    "        for val in self.classDict[uniqueClass]:\n",
    "            if val not in currentDF['Field'].unique():\n",
    "                x = 0\n",
    "                \n",
    "            if val in currentDF['Field'].unique():\n",
    "                currentIndex = self.classDict[uniqueClass].index(val)\n",
    "                tagNum = currentDF.loc[currentDF['Field'] == val, ['Tag Number']].values[0][0]\n",
    "                stringedTagNum = str(tagNum)\n",
    "                \n",
    "                i = 0\n",
    "                j = 0\n",
    "    \n",
    "                while i < currentIndex + 2:\n",
    "                    \n",
    "                    lineNow = self.idf[num + j]\n",
    "                    \n",
    "                    i = i + searchTermsDict['ElementsPerLine'][j]\n",
    "                    j = j + 1\n",
    "                \n",
    "                tagged = pat.search(lineNow)\n",
    "                if tagged is None:\n",
    "                    new = lineNow.replace(searchTermsDict[f'{uniqueClass} --> {uniqueObject}'][currentIndex-1], f'@@tag{tagNum}@@', 1)\n",
    "                    \n",
    "                elif tagged is not None:\n",
    "                    lineArray = lineNow.split('@@')\n",
    "                    newLineNow = lineArray[-1]\n",
    "                    del lineArray[-1]\n",
    "                    newt = newLineNow.replace(searchTermsDict[f'{uniqueClass} --> {uniqueObject}'][currentIndex-1], f'@@tag{tagNum}@@', 1)\n",
    "                    new = '@@'.join(lineArray) + '@@' + newt\n",
    "\n",
    "                self.idf[num + j - 1] = new\n",
    "                self.tagNumSanityCheck.append(tagNum)\n",
    "       \n",
    "    \n",
    "    def createJEPlusIDF(self):\n",
    "        pattern = re.compile(r';')\n",
    "        matches = None\n",
    "        \n",
    "        for uniqueClass in self.uniqueClasses:\n",
    "            currentDF = self.df.loc[self.df['Class'] == uniqueClass, :]\n",
    "            numOfObjInClasses = len(currentDF['Object'].unique())\n",
    "            \n",
    "            if numOfObjInClasses == 1:\n",
    "                i = 0\n",
    "                while i < len(self.idf):\n",
    "                    line = self.idf[i]\n",
    "                    adjLine = line.split(',')[0]\n",
    "                    \n",
    "                    if len(adjLine) > 0:\n",
    "                        isClass = 1\n",
    "                    else:\n",
    "                        isClass = 0\n",
    "                    \n",
    "                    if adjLine not in self.uniqueClasses and isClass == 1:\n",
    "                        pattern = re.compile(';')\n",
    "                        matches = None\n",
    "                        \n",
    "                        while matches is None:\n",
    "                            line = self.idf[i]\n",
    "                            matches = pattern.search(line)\n",
    "                            if matches is not None:\n",
    "                                    break\n",
    "                            i = i + 1\n",
    "                        \n",
    "                    if adjLine == uniqueClass:\n",
    "                        self.oneObjectTagAdd(i, uniqueClass)\n",
    "                        break\n",
    "                    \n",
    "                    i = i + 1\n",
    "                    \n",
    "            if numOfObjInClasses != 1:\n",
    "                uniqueObjects = currentDF['Object'].unique()\n",
    "                \n",
    "                for uniqueObject in uniqueObjects:\n",
    "                    newCurrentDF = currentDF.loc[(currentDF['Class'] == uniqueClass) & (currentDF['Object'] == uniqueObject), :]\n",
    "                    j = 0\n",
    "                    \n",
    "                    while j < len(self.idf):\n",
    "                        line = self.idf[j]\n",
    "                        adjLine = line.split(',')[0]\n",
    "                        \n",
    "                        if len(adjLine) > 0:\n",
    "                            isClass = 1\n",
    "                        else:\n",
    "                            isClass = 0\n",
    "                        \n",
    "                        if adjLine not in self.uniqueClasses and isClass == 1:\n",
    "                            pattern = re.compile(';')\n",
    "                            matches = None\n",
    "                    \n",
    "                            while matches is None:\n",
    "                                line = self.idf[j]\n",
    "                                matches = pattern.search(line)\n",
    "                                if matches is not None:\n",
    "                                    break\n",
    "                                j = j + 1\n",
    "                        \n",
    "                        if adjLine == uniqueClass:\n",
    "                            uo = self.getClassObject(j).strip()\n",
    "                        \n",
    "                        if adjLine == uniqueClass and uo == uniqueObject:\n",
    "                            self.multipleObjectTagAdd(j, uniqueClass, uniqueObject)\n",
    "                            break\n",
    "                            \n",
    "                        j = j + 1\n",
    "                        \n",
    "                    \n",
    "    def createParameterCSV(self):\n",
    "        tagNums = []\n",
    "        ids = []\n",
    "        names = []\n",
    "        paramTypes = []\n",
    "        descriptions = []\n",
    "        searchStrings = []\n",
    "        selectedValueIndexes = []\n",
    "        valueTypes = []\n",
    "        valueStrings = []\n",
    "        \n",
    "        default_col_num = self.full_df.columns.get_loc('Default')\n",
    "        min_col_num = self.full_df.columns.get_loc('Minimum')\n",
    "        max_col_num = self.full_df.columns.get_loc('Maximum')\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(self.full_df):\n",
    "            tagNums.append(i)\n",
    "            \n",
    "            ids.append('P' + str(i))\n",
    "            \n",
    "            Class = self.full_df['Class'][i]\n",
    "            obj = self.full_df['Object'][i]\n",
    "            field = self.full_df['Field'][i]\n",
    "            \n",
    "            names.append(obj + ' ' + field)\n",
    "            \n",
    "            paramTypes.append('PARAMETRICS')\n",
    "            \n",
    "            descriptions.append(Class + ' - ' + obj + ' ' + field)\n",
    "            \n",
    "            searchStrings.append('@@tag' + str(i) + '@@')\n",
    "            \n",
    "            selectedValueIndexes.append(0)\n",
    "            \n",
    "            valueTypes.append('DOUBLE')\n",
    "            \n",
    "            val1 = self.full_df.iloc[i, default_col_num]\n",
    "            val2 = self.full_df.iloc[i, min_col_num]\n",
    "            val3 = self.full_df.iloc[i, max_col_num]\n",
    "    \n",
    "            valueStrings.append(f'{{{val1}, {val2}, {val3}}}')\n",
    "            \n",
    "            i = i + 1\n",
    "            \n",
    "        SAparams = pd.DataFrame({'# ID': ids, 'Name': names, 'Parameter Type': paramTypes, 'Description': descriptions,\n",
    "                         'Search String': searchStrings, 'Value Type': valueTypes, 'Value String': valueStrings,\n",
    "                        'Selected Value Index': selectedValueIndexes})\n",
    "        \n",
    "        return SAparams\n",
    "    \n",
    "    \n",
    "    def createJobsCSVandJSON(self):  \n",
    "        the_list = [self.full_df['Default'].values.copy()]\n",
    "        max_jobs_list = []\n",
    "        min_jobs_list = []\n",
    "        jobsDict = {}\n",
    "        minJobNum = 2\n",
    "        maxJobNum = 3\n",
    "        for index, row in self.full_df.iterrows():\n",
    "            default = row['Default']\n",
    "            maximum = row['Maximum']\n",
    "            minimum = row['Minimum']\n",
    "    \n",
    "            def_vals = self.full_df['Default'].values.copy()\n",
    "            max_vals = self.full_df['Default'].values.copy()\n",
    "            min_vals = self.full_df['Default'].values.copy()\n",
    "    \n",
    "            max_vals[index] = maximum\n",
    "            min_vals[index] = minimum\n",
    "            \n",
    "            max_jobs_list.append(maximum)\n",
    "            min_jobs_list.append(minimum)\n",
    "    \n",
    "            the_list.append(list(min_vals))\n",
    "            the_list.append(list(max_vals))\n",
    "            \n",
    "            theClass = row['Class']\n",
    "            theObject = row['Object']\n",
    "            theField = row['Field']\n",
    "            \n",
    "            name = theClass + '-->' + theObject + '-->' + theField\n",
    "            jobsDict[name] = {}\n",
    "            jobsDict[name]['Default'] = default\n",
    "            jobsDict[name]['MinJobNum'] = minJobNum\n",
    "            jobsDict[name]['Min'] = minimum\n",
    "            jobsDict[name]['MaxJobNum'] = maxJobNum\n",
    "            jobsDict[name]['Max'] = maximum\n",
    "            \n",
    "            minJobNum = minJobNum + 2\n",
    "            maxJobNum = maxJobNum + 2\n",
    "            \n",
    "        jobs_df = pd.DataFrame(np.array(the_list))\n",
    "        minimax_jobs_df = pd.DataFrame([min_jobs_list, max_jobs_list])\n",
    "        \n",
    "        jobs_df.insert(0, \"Job Name\", 'Job', True)\n",
    "        jobs_df.insert(1, \"IDF File\", 0, True)\n",
    "        jobs_df.insert(2, \"Weather File\", 0, True)\n",
    "        \n",
    "        minimax_jobs_df.insert(0, \"Job Name\", 'Job', True)\n",
    "        minimax_jobs_df.insert(1, \"IDF File\", 0, True)\n",
    "        minimax_jobs_df.insert(2, \"Weather File\", 0, True)\n",
    "        \n",
    "        return jobs_df, jobsDict, minimax_jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deluxe-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "idfFile = \"..\\IDF_Files\\Building.idf\"\n",
    "iddFile = \"..\\IDD_Files\\V85_Energy+.idd\"\n",
    "paramFile = \"../UncertaintyAnalysis/Filtered_TuneableParameters.csv\"\n",
    "\n",
    "jeplus = JEPlusSensitivityAnalysis(idfFile, iddFile, paramFile)\n",
    "\n",
    "writeIDF = False\n",
    "IDFname = 'Building_IDF4JEPlus.idf'\n",
    "\n",
    "writeJEPlusParams = False\n",
    "JEPlusParamsName = 'Building_Parmas4JEPlus.csv'\n",
    "\n",
    "writeJEPLusJobsCSV = False\n",
    "JEPlusJobsCSVName = 'Building_Jobs4JEPlus.csv'\n",
    "\n",
    "writeJEPLusJobsJSON = False\n",
    "JEPlusJobsJSONName = 'Building_JSON_Jobs.json'\n",
    "\n",
    "writeMinimaxJobsCSV = False\n",
    "MinimaxJobsCSVName = 'BuildingMinimaxJobs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ordinary-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1573 tags have been added to the IDF!\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(jeplus.tagNumSanityCheck)} tags have been added to the IDF!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "silent-accordance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tags have been added. None are missing!\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "l = 0\n",
    "\n",
    "while k < len(jeplus.full_df):\n",
    "    if k not in jeplus.tagNumSanityCheck:\n",
    "        print(f'@@tag{k}@@ could not be added!')\n",
    "        l = 1\n",
    "        \n",
    "    k = k + 1\n",
    "    \n",
    "if l == 0:\n",
    "    print('All tags have been added. None are missing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gorgeous-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if writeIDF:\n",
    "    f = open(IDFname, \"a\")\n",
    "    for l in jeplus.idf:\n",
    "        f.writelines(l + '\\n')\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "if writeJEPlusParams:\n",
    "    jeplus.jEplusParameters.to_csv(JEPlusParamsName, index=False)\n",
    "    \n",
    "if writeJEPLusJobsCSV:\n",
    "    jeplus.jEplusJobs.to_csv(JEPlusJobsCSVName, index=False, header=False)\n",
    "    \n",
    "if writeJEPLusJobsJSON:\n",
    "    with open(JEPlusJobsJSONName, 'w') as json_file:\n",
    "        json.dump(jeplus.jobsDict, json_file)\n",
    "    \n",
    "    json_file.close()\n",
    "    \n",
    "if writeMinimaxJobsCSV:\n",
    "    jeplus.minimax_jobs_df.to_csv(MinimaxJobsCSVName, index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
